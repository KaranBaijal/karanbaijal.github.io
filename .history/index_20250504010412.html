<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Karan Baijal</title>

  <meta name="author" content="Karan Baijal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Karan Baijal
                  </p>
                  <p>
                    I am currently a masters student at Cornell University in Computer Science with a focus in Robotics
                    and Machine Learning. I recieved my undergraduate degree from Cornell University majoring in Physics
                    with double minors in Computer Science and Mechanical Engineering.
                  </p>
                  <p>
                    I am an intrinsically curious person who enjoys constant learning and implementation. I love working
                    on challenging problems and enjoy the process of working through complex problems for long hours and
                    days.
                  </p>
                  <p>
                    My primary professional interests are in Robotics, Machine Learning, and Quantum Computing. Outside
                    of work, I like to play soccer and baskbetball.
                    I enjoy playing the guitar and piano, and I also do photography!
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:kb553@cornell.edu">Email</a> &nbsp;/&nbsp;
                    <a href="data/KaranBaijalCornellResume.pdf">CV</a> &nbsp;/&nbsp;
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                    <a href="https://github.com/karanbaijal/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:37%;max-width:37%">
                  <a href="images/Karan_Formal_Pic.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/Karan_Formal_Pic.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <!-- <p>
                    I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my
                    research is about inferring the physical world (shape, motion, color, light, etc) from images,
                    usually with radiance fields. Some papers are <span class="highlight">highlighted</span>.
                  </p>
                -->
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <!-- Project 1: CLAMP -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='carbon_image'>
                      <!-- This video section can be removed if you don't have a video -->
                      <video width=100% height=100% muted autoplay loop>
                        <source src="" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/1.jpg' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://drive.google.com/file/d/1rzpVZlt2BLw1Wf0sOP0_0WX0rACy6Ntr/view?usp=share_link">
                    <span class="papertitle">CLAMP: Crowdsourcing a LArge-scale in-the-wild haptic dataset with an
                      open-source device for Multimodal robot Perception</span>
                  </a>
                  <em>Robotics: Science and Systems </em>, 2025
                  <br>
                  <a
                    href="https://drive.google.com/file/d/1rzpVZlt2BLw1Wf0sOP0_0WX0rACy6Ntr/view?usp=share_link">Paper</a>
                  <p></p>
                  <p>
                    Developed the largest multimodal haptic dataset in literature. Implemented Transformer and CNN-based
                    multimodal haptic model and fused it with finetuned Vision-Language models (OpenAI CLIP, GPT) to
                    develop a visuo-haptic model for material and compliance recognition.
                    Implemented model on multiple robot manipulators and real-world tasks to show generalization and
                    robustness of model. Achieved significant performance improvement over state-of-the-art models.
                  </p>
                </td>
              </tr>

              <!-- Project 2: Diffusion Robot -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='carbon_image'>
                      <!-- This video section can be removed if you don't have a video -->
                      <video width=100% height=100% muted autoplay loop>
                        <source src="" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/robot_img.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://drive.google.com/file/d/1rtvwEXJm89opEaa4xVZc89XH4HucC8oL/view">
                    <span class="papertitle">RoboChef: Meal-Preperation using Single-arm Robot </span>
                  </a>
                  <em> (Currently ongoing work)
                    <br>
                    <a href="https://drive.google.com/file/d/1rtvwEXJm89opEaa4xVZc89XH4HucC8oL/view">Paper</a>
                    <p></p>
                    <p>
                      RoboChef is the first robotic meal-preparation system to seamlessly integrate vegetable cutting
                      and peeling with sandwich assembly, and does so with a single robot-arm.
                      It combines a diffusion-based control policy for precise manipulation, advanced image segmentation
                      for reliable perception, and an LLM-driven planner to orchestrate every step of the
                      sandwich-making
                      process.
                    </p>
                </td>
              </tr>

              <!-- Project 3: AdaTAMP -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='carbon_image'>
                      <!-- This video section can be removed if you don't have a video -->
                      <video width=100% height=100% muted autoplay loop>
                        <source src="" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/agent_image.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://openreview.net/pdf?id=Dxzr4SyHwe">
                    <span class="papertitle">RoboChef: Meal-Preperation using Single-arm Robot </span>
                  </a>
                  <em> International Conference on Robotics and Automation (ICRA) </em>, 2025
                  <br>
                  <a href="https://openreview.net/pdf?id=Dxzr4SyHwe">Paper</a>
                  <p></p>
                  <p>
                    We introduce AdaTAMP, an Adaptive Task and Motion Planning framework that integrates LLM-based task
                    planning with continuous motion planning via a real-time feedback loop, enabling error correction
                    and multi-agent collaboration for embodied agents.
                    AdaTAMP significantly outperforms baseline methods in success rate, planning efficiency, and
                    adaptability, particularly for complex, long-horizon, multi-agent scenarios.
                    Accepted Poster Submission at ICRA: Task and Motion Planning Workshop 2025.
                  </p>
                </td>
              </tr>

              <!-- Project 4: LHC Research -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='carbon_image'>
                      <!-- This video section can be removed if you don't have a video -->
                      <video width=100% height=100% muted autoplay loop>
                        <source src="" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/LHCCollision.jpg' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://drive.google.com/file/d/1O5W_Ye5CoG3JDNm_LgjhDMQLBZlqU6Sv/view?usp=share_link">
                    <span class="papertitle"> Search for inelastic dark matter in events with soft, displaced electrons
                      and missing transverse momentum </span>
                  </a>
                  <em> (Ongoing Research)
                    <br>
                    <a
                      href="https://drive.google.com/file/d/1O5W_Ye5CoG3JDNm_LgjhDMQLBZlqU6Sv/view?usp=share_link">Paper</a>
                    <p></p>
                    <p>
                      Trained machine learning models using boosted decision trees to determine feature importance &
                      differentiate Dark matter signal from Standard Model background events during proton-proton
                      collisions in CERN particle collider. Additionally, developed a novel isolation metric to resolve
                      a flaw in CERN’s codebase, improving performance by 15%. Wrote Python and
                      C++ code on Fermilab GPU servers as part of a global, multi-collaborative effort. Aiming to submit
                      paper by June 2025.
                    </p>
                </td>
              </tr>


              <!-- Research 5: Quantum Computing Research -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='carbon_image'>
                      <!-- This video section can be removed if you don't have a video -->
                      <video width=100% height=100% muted autoplay loop>
                        <source src="" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/agent_image.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://openreview.net/pdf?id=Dxzr4SyHwe">
                    <span class="papertitle"> </span>
                  </a>
                  <em>
                    <br>
                    <a href="https://openreview.net/pdf?id=Dxzr4SyHwe">Paper</a>
                    <p></p>
                    <p>
                      I worked on the LHC experiment at CERN, where I developed single and multi-object boosting.
                    </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
            <tbody>
              <tr>
                <td>
                  <h2>Projects</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- Research 5: Quantum Computing Research -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='carbon_image'>
                      <!-- This video section can be removed if you don't have a video -->
                      <video width=100% height=100% muted autoplay loop>
                        <source src="" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src='img/agent_image.png' width="160">
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://openreview.net/pdf?id=Dxzr4SyHwe">
                    <span class="papertitle"> </span>
                  </a>
                  <em>
                    <br>
                    <a href="https://openreview.net/pdf?id=Dxzr4SyHwe">Paper</a>
                    <p></p>
                    <p>
                      I worked on the LHC experiment at CERN, where I developed single and multi-object boosting.
                    </p>
                </td>
              </tr>

              <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
                <tbody>
                  <tr>
                    <td>
                      <h2>Extra</h2>
                    </td>
                  </tr>
                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


                  <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()" bgcolor="#ffffd0">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='bolt3d_image'><video width=100% height=100% muted autoplay loop>
                            <source src="images/bolt3d.mp4" type="video/mp4">
                            Your browser does not support the video tag.

                          </video></div>
                        <img src='images/bolt3d.jpg' width="160">
                      </div>
                      <script type="text/javascript">
                        function bolt3d_start() {
                          document.getElementById('bolt3d_image').style.opacity = "1";
                        }

                        function bolt3d_stop() {
                          document.getElementById('bolt3d_image').style.opacity = "0";
                        }
                        bolt3d_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://szymanowiczs.github.io/bolt3d">
                        <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
                      </a>
                      <br>
                      <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
                      <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
                      <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
                      <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
                      <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
                      <a href="https://holynski.org">Aleksander Holynski</a>,
                      <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://henzler.github.io">Philipp Henzler</a>
                      <br>
                      <em>arXiv</em>, 2025
                      <br>
                      <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
                      /
                      <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
                      <p></p>
                      <p>
                        By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds
                        on a
                        single GPU) feed-forward 3D scene generation.
                      </p>
                    </td>
                  </tr>

                  <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()" bgcolor="#ffffd0">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='cat4d_image'><video width=100% height=100% muted autoplay loop>
                            <source src="images/cat4d.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/cat4d.jpg' width="160">
                      </div>
                      <script type="text/javascript">
                        function cat4d_start() {
                          document.getElementById('cat4d_image').style.opacity = "1";
                        }

                        function cat4d_stop() {
                          document.getElementById('cat4d_image').style.opacity = "0";
                        }
                        cat4d_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://cat-4d.github.io/">
                        <span class="papertitle">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
                        </span>
                      </a>
                      <br>
                      <a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
                      <a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
                      <a href="https://poolio.github.io/">Ben Poole</a>,
                      <a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
                      <a href="https://www.cs.columbia.edu/~cxz/index.htm/">Changxi Zheng</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://holynski.org/">Aleksander Holynski</a>
                      <br>
                      <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                      <br>
                      <a href="https://cat-4d.github.io/">project page</a>
                      /
                      <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
                      <p></p>
                      <p>
                        An approach for turning a video into a 4D radiance field that can be rendered in real-time. When
                        combined with a text-to-video model, this enables text-to-4D.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='r2r_image'><video width=100% muted autoplay loop>
                            <source src="images/r2r.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/r2r.jpg' width=100%>
                      </div>
                      <script type="text/javascript">
                        function r2r_start() {
                          document.getElementById('r2r_image').style.opacity = "1";
                        }

                        function r2r_stop() {
                          document.getElementById('r2r_image').style.opacity = "0";
                        }
                        r2r_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://relight-to-reconstruct.github.io/">
                        <span class="papertitle">Generative Multiview Relighting for
                          3D Reconstruction under Extreme Illumination Variation</span>
                      </a>
                      <br>
                      <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
                      <a href="https://henzler.github.io/">Philipp Henzler</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
                      <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
                      <a href="https://dorverbin.github.io/">Dor Verbin</a>
                      <br>
                      <em>CVPR</em>, 2025 &nbsp <font color=#FF8080><strong>(Highlight)</strong></font>
                      <br>
                      <a href="https://relight-to-reconstruct.github.io/">project page</a>
                      /
                      <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
                      <p></p>
                      <p>
                        Images taken under extreme illumination variation can be made consistent with diffusion, and
                        this
                        enables high-quality 3D reconstruction.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="simvs_stop()" onmouseover="simvs_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='simvs_image'><video width=100% muted autoplay loop>
                            <source src="images/simvs.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/simvs.jpg' width=100%>
                      </div>
                      <script type="text/javascript">
                        function simvs_start() {
                          document.getElementById('simvs_image').style.opacity = "1";
                        }

                        function simvs_stop() {
                          document.getElementById('simvs_image').style.opacity = "0";
                        }
                        simvs_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://alextrevithick.github.io/simvs/">
                        <span class="papertitle">SimVS: Simulating World Inconsistencies for Robust View
                          Synthesis</span>
                      </a>
                      <br>
                      <a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
                      <a href="https://scholar.google.com/citations?user=-KSDNZQAAAAJ&hl=en">Roni Paiss</a>,
                      <a href="https://henzler.github.io/">Philipp Henzler</a>,
                      <a href="https://dorverbin.github.io/">Dor Verbin</a>,
                      <a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
                      <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
                      <a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
                      <a href="https://poolio.github.io/">Ben Poole</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://holynski.org/">Aleksander Holynski</a>,
                      <a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
                      <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>
                      <br>
                      <em>CVPR</em>, 2025
                      <br>
                      <a href="https://alextrevithick.github.io/simvs/">project page</a>
                      /
                      <a href="https://arxiv.org/abs/2412.07696">arXiv</a>
                      <p></p>
                      <p>
                        Simulating the world with video models lets you make inconsistent captures consistent.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="power_stop()" onmouseover="power_start()" bgcolor="#ffffd0">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='power_image'><video width=100% height=100% muted autoplay loop>
                            <source src="images/power.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/power.png' width="160">
                      </div>
                      <script type="text/javascript">
                        function power_start() {
                          document.getElementById('power_image').style.opacity = "1";
                        }

                        function power_stop() {
                          document.getElementById('power_image').style.opacity = "0";
                        }
                        power_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://x.com/jon_barron/status/1891918200931061996">
                        <span class="papertitle">A Power Transform
                        </span>
                      </a>
                      <br>
                      <strong>Jonathan T. Barron</strong>
                      <br>
                      <em>arXiv</em>, 2025
                      <br>
                      <a href="https://x.com/jon_barron/status/1891918200931061996">tweet</a>
                      /
                      <a href="https://arxiv.org/abs/2502.10647">arXiv</a>
                      <p></p>
                      <p>
                        A slight tweak to the Box-Cox power transform generalizes a variety of curves, losses, kernel
                        functions, probability distributions, bump functions, and neural network activation functions.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="ever_stop()" onmouseover="ever_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='ever_image'>
                          <img src='images/ever_after.png' width=100%>
                        </div>
                        <img src='images/ever_before.png' width=100%>
                      </div>
                      <script type="text/javascript">
                        function ever_start() {
                          document.getElementById('ever_image').style.opacity = "1";
                        }

                        function ever_stop() {
                          document.getElementById('ever_image').style.opacity = "0";
                        }
                        ever_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://half-potato.gitlab.io/posts/ever/">
                        <span class="papertitle">EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis
                        </span>
                      </a>
                      <br>
                      <a href="https://half-potato.gitlab.io/">Alexander Mai</a>,
                      <a href="https://phogzone.com/">Peter Hedman</a>,
                      <a href="https://grgkopanas.github.io/">George Kopanas</a>,
                      <a href="https://dorverbin.github.io/">Dor Verbin</a>,
                      <a href="https://scholar.google.com/citations?user=ozNFrecAAAAJ&hl=en">David Futschik</a>,
                      <a href="https://xharlie.github.io/">Qiangeng Xu</a>,
                      <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://www.zhangyinda.com/">Yinda Zhang</a>
                      <br>
                      <em>arXiv</em>, 2024
                      <br>
                      <a href="https://half-potato.gitlab.io/posts/ever/">project page</a>
                      /
                      <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
                      <p></p>
                      <p>
                        Raytracing constant-density ellipsoids yields more accurate and flexible radiance fields than
                        splatting Gaussians, and still runs in real-time.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='cat3d_image'><video width=100% height=100% muted autoplay loop>
                            <source src="images/cat3d.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/cat3d.jpg' width="160">
                      </div>
                      <script type="text/javascript">
                        function cat3d_start() {
                          document.getElementById('cat3d_image').style.opacity = "1";
                        }

                        function cat3d_stop() {
                          document.getElementById('cat3d_image').style.opacity = "0";
                        }
                        cat3d_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://cat3d.github.io/">
                        <span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models
                        </span>
                      </a>
                      <br>
                      <a href="https://ruiqigao.github.io/">Ruiqi Gao</a>*,
                      <a href="https://holynski.org/">Aleksander Holynski</a>*,
                      <a href="https://henzler.github.io/">Philipp Henzler</a>,
                      <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
                      <a href="http://ricardomartinbrualla.com/">Ricardo Martin Brualla</a>,
                      <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://poolio.github.io/">Ben Poole</a>*

                      <br>
                      <em>NeurIPS</em>, 2024 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                      <br>
                      <a href="https://cat3d.github.io/">project page</a>
                      /
                      <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
                      <p></p>
                      <p>
                        A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view
                        reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="nerfcasting_stop()" onmouseover="nerfcasting_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='nerfcasting_image'><video width=100% muted autoplay loop>
                            <source src="images/nerfcasting.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/nerfcasting.jpg' width=100%>
                      </div>
                      <script type="text/javascript">
                        function nerfcasting_start() {
                          document.getElementById('nerfcasting_image').style.opacity = "1";
                        }

                        function nerfcasting_stop() {
                          document.getElementById('nerfcasting_image').style.opacity = "0";
                        }
                        nerfcasting_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://nerf-casting.github.io/">
                        <span class="papertitle">NeRF-Casting: Improved View-Dependent Appearance with Consistent
                          Reflections</span>
                      </a>
                      <br>

                      <a href="https://dorverbin.github.io/">Dor Verbin</a>,
                      <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                      <a href="https://phogzone.com/">Peter Hedman</a>,
                      <a href="https://benattal.github.io/">Benjamin Attal</a>, <br>
                      <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                      <a href="https://szeliski.org/RichardSzeliski.htm">Richard Szeliski</a>,
                      <strong>Jonathan T. Barron</strong>
                      <br>
                      <em>SIGGRAPH Asia</em>, 2024
                      <br>
                      <a href="https://nerf-casting.github.io/">project page</a>
                      /
                      <a href="https://arxiv.org/abs/2405.14871">arXiv</a>
                      <p></p>
                      <p>
                        Carefully casting reflection rays lets us synthesize photorealistic specularities in real-world
                        scenes.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="flash_cache_stop()" onmouseover="flash_cache_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='flash_cache_image'><video width=100% muted autoplay loop>
                            <source src="images/flash_cache.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/flash_cache.jpg' width=100%>
                      </div>
                      <script type="text/javascript">
                        function flash_cache_start() {
                          document.getElementById('flash_cache_image').style.opacity = "1";
                        }

                        function flash_cache_stop() {
                          document.getElementById('flash_cache_image').style.opacity = "0";
                        }
                        flash_cache_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://benattal.github.io/flash-cache/">
                        <span class="papertitle">Flash Cache: Reducing Bias in Radiance Cache Based Inverse
                          Rendering</span>
                      </a>
                      <br>
                      <a href="https://benattal.github.io/">Benjamin Attal</a>,
                      <a href="https://dorverbin.github.io/">Dor Verbin</a>,
                      <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                      <a href="https://phogzone.com/">Peter Hedman</a>, <br>
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://www.cs.cmu.edu/~motoole2/">Matthew O'Toole</a>,
                      <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>
                      <br>
                      <em>ECCV</em>, 2024 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                      <br>
                      <a href="https://benattal.github.io/flash-cache/">project page</a>
                      /
                      <a href="TODO">arXiv</a>
                      <p></p>
                      <p>
                        A more physically-accurate inverse rendering system based on radiance caching for recovering
                        geometry, materials, and lighting from RGB images of an object or scene.
                      </p>
                    </td>
                  </tr>



                  <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='nuvo_image'><video width=100% muted autoplay loop>
                            <source src="images/nuvo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/nuvo.jpg' width=100%>
                      </div>
                      <script type="text/javascript">
                        function nuvo_start() {
                          document.getElementById('nuvo_image').style.opacity = "1";
                        }

                        function nuvo_stop() {
                          document.getElementById('nuvo_image').style.opacity = "0";
                        }
                        nuvo_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://pratulsrinivasan.github.io/nuvo/">
                        <span class="papertitle">Nuvo: Neural UV Mapping for Unruly 3D Representations</span>
                      </a>
                      <br>
                      <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                      <a href="http://stephangarbin.com/">Stephan J. Garbin</a>,
                      <a href="https://dorverbin.github.io/">Dor Verbin</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://bmild.github.io/">Ben Mildenhall</a>
                      <br>
                      <em>ECCV</em>, 2024
                      <br>
                      <a href="https://pratulsrinivasan.github.io/nuvo/">project page</a>
                      /
                      <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>
                      /
                      <a href="http://arxiv.org/abs/2312.05283">arXiv</a>
                      <p></p>
                      <p>
                        Neural fields let you recover editable UV mappings for the challenging geometries produced by
                        NeRF-like models.
                      </p>
                    </td>
                  </tr>


                  <tr onmouseout="bog_stop()" onmouseover="bog_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='bog_image'><video width=100% muted autoplay loop>
                            <source src="images/bog.jpg" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/bog.jpg' width=100%>
                      </div>
                      <script type="text/javascript">
                        function bog_start() {
                          document.getElementById('bog_image').style.opacity = "1";
                        }

                        function bog_stop() {
                          document.getElementById('bog_image').style.opacity = "0";
                        }
                        bog_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://creiser.github.io/binary_opacity_grid/">
                        <span class="papertitle">Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based
                          View
                          Synthesis
                        </span>
                      </a>
                      <br>
                      <a href="https://creiser.github.io/">Christian Reiser</a>,
                      <a href="http://stephangarbin.com/">Stephan J. Garbin</a>,
                      <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                      <a href="https://dorverbin.github.io/">Dor Verbin</a>,
                      <a href="https://szeliski.org/RichardSzeliski.htm">Richard Szeliski</a>,
                      <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                      <strong>Jonathan T. Barron</strong>,
                      <a href="https://phogzone.com/">Peter Hedman</a>*,
                      <a href="https://www.cvlibs.net/">Andreas Geiger</a>*
                      <br>
                      <em>SIGGRAPH</em>, 2024
                      <br>
                      <a href="https://creiser.github.io/binary_opacity_grid/">project page</a>
                      /
                      <a href="https://www.youtube.com/watch?v=2TPUmGRg8bM">video</a>
                      /
                      <a href="https://arxiv.org/abs/2402.12377">arXiv</a>
                      <p></p>
                      <p>
                        Applying anti-aliasing to a discrete opacity grid lets you render a hard representation into a
                        soft
                        image, and this enables highly-detailed mesh recovery.
                      </p>
                    </td>
                  </tr>

                  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                            <source src="images/smerf.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video></div>
                        <img src='images/smerf.jpg' width=100%>
                      </div>
                      <script type="text/javascript">
                        function smerf_start() {
                          document.getElementById('smerf_image').style.opacity = "1";
                        }

                        function smerf_stop() {
                          document.getElementById('smerf_image').style.opacity = "0";
                        }
                        smerf_stop()
                      </script>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://smerf-3d.github.io/">
                        <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time
                          Large-Scene Exploration</span>
                      </a>
                      <br>
                      <a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth*</a>,
                      <a href="https://phogzone.com/">Peter Hedman*</a>,
                      <a href="https://creiser.github.io/">Christian Reiser</a>,
                      <a href="">Peter Zhizhin</a>,
                      <a href="">Jean-François Thibert</a>,
                      <a href="https://lucic.ai/">Mario Lučić</a>,
                      <a href="https://szeliski.org/">Richard Szeliski</a>,
                      <strong>Jonathan T. Barron</strong>
                      <br>
                      <em>SIGGRAPH</em>, 2024 &nbsp <font color="red"><strong>(Honorable Mention)</strong></font>
                      <br>
                      <a href="https://smerf-3d.github.io/">project page</a>
                      /
                      <a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a>
                      /
                      <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
                      <p></p>
                      <p>
                        Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops
                        and
                        smartphones at 60 FPS.
                      </p>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <img src="images/prl.jpg" alt="prl" width="160" height="160">
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                        <span class="papertitle">Parallelizing Reinforcement Learning</span>
                      </a>
                      <br>
                      <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave
                        Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>
                      <br>
                      <em>Technical Report</em>, 2009
                      <br>
                      <a href="data/BarronPRL2009.bib">bibtex</a>
                      <p>Markov Decision Problems which lie in a low-dimensional latent space can be decomposed,
                        allowing
                        modified RL algorithms to run orders of magnitude faster in parallel.</p>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                        <span class="papertitle">Blind Date: Using Proper Motions to Determine the Ages of Historical
                          Images</span>
                      </a>
                      <br>
                      <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a
                        href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a
                        href="http://cs.nyu.edu/~roweis/">Sam
                        Roweis</a>
                      <br>
                      <em>The Astronomical Journal</em>, 136, 2008
                      <p>Using the relative motions of stars we can accurately estimate the date of origin of historical
                        astronomical images.</p>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                        <span class="papertitle">Cleaning the USNO-B Catalog Through Automatic Detection of Optical
                          Artifacts</span>
                      </a>
                      <br>
                      <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a
                        href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a
                        href="http://www.astro.princeton.edu/~dstn/">Dustin
                        Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                      <br>
                      <em>The Astronomical Journal</em>, 135, 2008
                      <p>We use computer vision techniques to identify and remove diffraction spikes and reflection
                        halos in
                        the USNO-B Catalog.</p>
                      <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
                    </td>
                  </tr>

                </tbody>
              </table>


              <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
                <tbody>
                  <tr>
                    <td>
                      <h2>Miscellanea</h2>
                    </td>
                  </tr>
                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


                  <tr>
                    <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                      <div class="colored-box" style="background-color: #fcb97d;">
                        <h2>Micropapers</h2>
                      </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                      <br>
                      <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain
                        Functions</a>
                      <br>
                      <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear
                        Units</a>
                      <br>
                      <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models:
                        How
                        Can Academics Adapt?</a>
                    </td>
                  </tr>


                  <tr>
                    <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                      <div class="colored-box" style="background-color: #aaba9e;">
                        <h2>Recorded Talks</h2>
                      </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:center">
                      <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative
                        Media, 2025</a><br>
                      <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                      <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
                      </a><br>
                      <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
                      <a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
                      <a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
                    </td>
                  </tr>

                  <tr>
                    <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                      <div class="colored-box" style="background-color: #c6b89e;">
                        <h2>Academic Service</h2>
                      </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:center">
                      <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                      <br>
                      <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                      <br>
                      <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                      <br>
                      <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                      <br>
                      <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                      <br>
                      <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR
                        2021</a>
                      <br>
                      <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                      <br>
                      <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                    </td>
                  </tr>



                  <tr>
                    <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                      <div class="colored-box" style="background-color: #edd892;">
                        <h2>Teaching</h2>
                      </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:center">
                      <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student
                        Instructor,
                        CS188 Spring 2011</a>
                      <br>
                      <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student
                        Instructor,
                        CS188 Fall 2010</a>
                      <br>
                      <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
                        Edition</a>
                    </td>
                  </tr>

                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:right;font-size:small;">
                        Feel free to steal this website's <a
                          href="https://github.com/jonbarron/jonbarron_website">source
                          code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes
                        analytics
                        tags that you do not want on your own website &mdash; use the github code instead. Also,
                        consider
                        using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a
                          href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>